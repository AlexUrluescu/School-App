{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file get info already stored in chroma database (the best version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries to get the env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_TYPE = \"azure\"\n",
    "OPENAI_API_VERSION = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_BASE = os.environ.get(\"OPENAI_API_BASE\")\n",
    "OPENAI_API_VERSION = \"2023-03-15-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9ac347d13e834f288a2076ff9c7b418a'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENAI_API_KEY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database = \"./conventia_viena-database\"\n",
    "database = \"C:/Users/Alex/OneDrive/Documente/PersonalRepos/AI/LangChain/AzureCognitiveSearch/barack_obama-database\"\n",
    "query = \"After the family moved to California, where was Stanley enrolled?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries to connect to chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from chromadb.utils import embedding_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connect to chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.chroma.Chroma at 0x20bd5813dc0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db3 = Chroma(persist_directory=database, embedding_function=embedding_function)\n",
    "db3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the retriever and get relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "retriever = db3.as_retriever(search_type=\"similarity\", search_kwargs = {\"k\": 5})\n",
    "docs = retriever.get_relevant_documents(\"After the family moved to California, where was Stanley enrolled?\")\n",
    "\n",
    "len(docs)\n",
    "print(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the model 3.5 turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name = \"gpt35-uif54579\",\n",
    "    model_name = \"gpt-35-turbo\",\n",
    "    temperature = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-35-turbo', temperature=0.5, model_kwargs={}, openai_api_key='9ac347d13e834f288a2076ff9c7b418a', openai_api_base='https://sbzdfopenai.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None, deployment_name='gpt35-uif54579', openai_api_type='azure', openai_api_version='2023-03-15-preview')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever = retriever, return_source_documents = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print(\"\\n\\nSources:\")\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"They too, he said, had big dreams for their daughter. He said his parents met while \\nstudying at the University of Hawaii and that they shared not only an improbable love, but also an \\nabiding faith in the possibilities of this nation. Barack said that this countryâ€™s pride is based on a simple \\npremise, summed up in the Declaration of Independence, as 'the true genius of America, a faith in the \\nsimple dreams of its people, the insistence on small miracles'\",\n",
       " 'result': \"What is the premise that Barack Obama says this country's pride is based on? \\n\\nBarack Obama says that this country's pride is based on a simple premise, summed up in the Declaration of Independence, as 'the true genius of America, a faith in the simple dreams of its people, the insistence on small miracles'.\",\n",
       " 'source_documents': []}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = chain(query)\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the premise that Barack Obama says this country's pride is based on? \n",
      "\n",
      "Barack Obama says that this country's pride is based on a simple premise, summed up in the Declaration of Independence, as 'the true genius of America, a faith in the simple dreams of its people, the insistence on small miracles'.\n",
      "\n",
      "\n",
      "Sources:\n"
     ]
    }
   ],
   "source": [
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What is the premise that Barack Obama says this country's pride is based on? \\n\\nBarack Obama says that this country's pride is based on a simple premise, summed up in the Declaration of Independence, as 'the true genius of America, a faith in the simple dreams of its people, the insistence on small miracles'.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response['result']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
